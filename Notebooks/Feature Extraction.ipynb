{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape, Statistic, and Histogram Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "eb4785fcfa45492f8f99ae242b57f7b4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 512,
    "execution_start": 1681675860250,
    "source_hash": "125a7051",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from scipy import ndimage as nd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "fc57db2cd83d4085b99a40898b2b5ed9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3791,
    "execution_start": 1681675860784,
    "source_hash": "1530f9bd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/ATR_GT_Training.csv', header=None, names=['file','label'])\n",
    "df.file = df.file.map(lambda x: x.replace(\"'\",''))\n",
    "df['img'] = df.file.map(lambda x: nib.load('../data/' + str(x) + '.nii.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "4c4f700c74ae4e628a14e224209aba9f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1681675864580,
    "source_hash": "3f43dccc"
   },
   "outputs": [],
   "source": [
    "hist_labels = ['hist' + str(x) for x in range(0,10)]\n",
    "new_features = 'x y z xyz xcom ycom zcom max xmax ymax zmax mean median std variance skew kurtosis entropy'.split() + hist_labels\n",
    "df = df.reindex(columns = df.columns.tolist() + new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate and save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "acac495bf6dd488ba3c8552056de60b6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_start": 1681675864594,
    "source_hash": "d549c77",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 100 images.\n",
      "Finished 200 images.\n",
      "Finished 300 images.\n",
      "Finished 400 images.\n",
      "Finished 500 images.\n",
      "Finished 600 images.\n",
      "Finished 700 images.\n",
      "Finished 800 images.\n",
      "Finished 900 images.\n",
      "Finished 1000 images.\n",
      "Finished 1100 images.\n",
      "Finished 1200 images.\n",
      "Finished 1300 images.\n",
      "Finished 1400 images.\n",
      "Finished Feature Extraction\n"
     ]
    }
   ],
   "source": [
    "features_shape, features_stats, features_histogram = [], [], []\n",
    "\n",
    "for i, img in enumerate(df.img):\n",
    "    \n",
    "    data = img.get_fdata()\n",
    "    nonzero = data[np.nonzero(data)]\n",
    "    \n",
    "    # Shape Features\n",
    "    x,y,z = img.shape\n",
    "    num_pixels = x*y*z\n",
    "    max_dim = np.max(img.shape)\n",
    "    mid_dim = np.median(img.shape)\n",
    "    min_dim = np.min(img.shape)\n",
    "    \n",
    "    # Histogram\n",
    "    histogram = nd.histogram(nonzero,0,2700,4)\n",
    "    \n",
    "    # Statistical Features\n",
    "    mean = nd.mean(nonzero)\n",
    "    median = nd.median(nonzero)\n",
    "    max_ = np.max(nonzero)\n",
    "    std = nd.standard_deviation(nonzero)\n",
    "    var = nd.variance(nonzero)\n",
    "    skew = stats.skew(nonzero,axis=None)\n",
    "    kurtosis = stats.kurtosis(nonzero,axis=None)\n",
    "    entropy = stats.entropy(histogram)\n",
    "    \n",
    "    features_shape.append([x,y,z,num_pixels,max_dim,mid_dim,min_dim])\n",
    "    features_stats.append([mean,median,max_,std,var,skew,kurtosis,entropy])\n",
    "    features_histogram.append(list(histogram))\n",
    "    \n",
    "    if i % 100 == 0 and i != 0:\n",
    "        print('Finished ' + str(i) + ' images.')\n",
    "\n",
    "print('Finished Feature Extraction')\n",
    "np.save('features_shape.npy',    np.array(features_shape))\n",
    "np.save('features_stats.npy',    np.array(features_stats))\n",
    "np.save('features_histogram.npy',np.array(features_histogram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1472 images\n",
      "31 features\n"
     ]
    }
   ],
   "source": [
    "print(str(len(df)), 'images')\n",
    "print(str(len(df.columns)), 'features')"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "590043f071414faf98d3f611a936fe59",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
